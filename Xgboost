##########xgboost check################

import xgboost as xgb
import sklearn
from sklearn.model_selection  import train_test_split
from sklearn.preprocessing import LabelEncoder

predictors = ['speed', 'prd_grp_cd','int_att_fiber_ind','bill_type','auto_pmt_ind','Tech_cat','flag_channel_call','flag_channel_indirect','flag_channel_call_uverse','flag_channel_retail','flag_channel_online','flag_channel_mobile', 'cnt_compt','comp_charter','comp_cox','comp_comcast','flag_Central','flag_East','flag_West','dtv_flag','wirls_flag','iptv_flag','voip_flag','cterm12','flag_income_75_100','flag_income_100_125','flag_income_125_150','flag_income_150','dwlng_type_group','flag_AA','flag_Asian','flag_Hispanic','flag_max_comp_speed','hsld_chld_cnt','flag_risk_low','flag_risk_medium','flag_risk_high','ind_access','dma_cd_group','unlimited', 'BB_only']

tenure=5
pull_data(tenure)
clean_data(data0,data1,tenure,1)
pre_process_data(mdf0,1)
        
#X=mdf0[predictors]     
#y=mdf0['bb_churn']

# limit to categorical data using df.select_dtypes()
cat_vars = X.select_dtypes(include=[object])
df_processed = pd.get_dummies(X, prefix_sep="_", columns=cat_vars.columns) 
ga_process=pd.get_dummies(mdf_grossadd0[predictors], prefix_sep="_", columns=cat_vars.columns) 

def hot_encode():
    from sklearn import preprocessing
    le = preprocessing.LabelEncoder()
    X_2 = X.apply(le.fit_transform)
    X_2.head(10)
    enc = preprocessing.OneHotEncoder()
    
    # 2. FIT
    enc.fit(X_2)
    
    # 3. Transform
    onehotlabels = enc.transform(X_2).toarray()
    onehotlabels.shape
    
    return None

X_train, X_test, y_train, y_test = train_test_split(df_processed, y, test_size=0.2, random_state=42)

dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)
dGA = xgb.DMatrix(ga_process)



from xgboost import XGBRegressor, plot_importance 
xgb1 = XGBRegressor(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1000, gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=500,seed=27)

from matplotlib import pyplot

def modelfit(alg, X_train,y_train,X_test,y_test, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):
    global dga_predictions
    global pred_bb_series
    global pred_bb
    
    if useTrainCV:
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(X_train[predictors].values, label=y_train)
        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,
            metrics='auc', early_stopping_rounds=early_stopping_rounds)
        alg.set_params(n_estimators=cvresult.shape[0])
    
    #Fit the algorithm on the data
    alg.fit(X_train[predictors], y_train,eval_metric='auc')
        
    #Predict training set:
    dtrain_predictions = alg.predict(X_train[predictors])
    dtest_predictions = alg.predict(X_test[predictors])
    dga_predictions = alg.predict(ga_process[predictors])
    pred_bb_series = pd.Series(dga_predictions)
    pred_bb_series.name="p_{}".format(tenure)
    pred_bb=ga_process.merge(pred_bb_series, how='left', left_index=True, right_index=True)
    #dtrain_predprob = alg.predict_proba(X_train[predictors])[:,1]
        
    #Print model report:
    print ("\nvModel Report")
   # print ("Accuracy : %.4g" % metrics.accuracy_score(y_train, dtrain_predictions))
    print ("AUC Score (Train): %f" % roc_auc_score(y_train, dtrain_predictions))
    print ("AUC Score (Test): %f" % roc_auc_score(y_test, dtest_predictions))
    
    plot_importance(alg,max_num_features=20)
    pyplot.show()
    
#Choose all predictors 
predictors = X_train.columns    
modelfit(xgb1, X_train,y_train, X_test,y_test,predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=10)

# gb1 = XGBRegressor()
# parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower
#               'objective':['reg:linear'],
#               'learning_rate': [.03, 0.05, .07], #so called `eta` value
#               'max_depth': [5, 6, 7],
#               'min_child_weight': [4],
#               'silent': [1],
#               'subsample': [0.7],
#               'colsample_bytree': [0.7],
#               'n_estimators': [500]}x 


param = {
    'max_depth': 5,  # the maximum depth of each tree
    'eta': 0.01,  # the training step for each iteration
    'silent': 1,  # logging mode - quiet
    'objective': 'multi:softprob',  # error evaluation for multiclass training
    'num_class': 2}  # the number of classes that exist in this datset
num_round = 20  # the number of training iterations
bst = xgb.train(param, dtrain, num_round,eval_metric='auc')
xgb1 = XGBRegressor(
 learning_rate =0.1,
 n_estimators=100,
 max_depth=5,
 min_child_weight=1,
 gamma=0,
 subsample=0.8,
 colsample_bytree=0.8,
 objective= 'binary:logistic',
 nthread=4,
 scale_pos_weight=1,
 seed=27) 

############################################################################################
############################################################################################
from xgboost import XGBRegressor, plot_importance 


xgb1 = XGBRegressor(learning_rate =0.01, n_estimators=1000, max_depth=5, min_child_weight=200, gamma=0.0001, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',  nthread=4, scale_pos_weight=1, seed=27)

from matplotlib import pyplot

def modelfit(alg, X_train,y_train,X_test,y_test, predictors,useTrainCV=False, cv_folds=5, early_stopping_rounds=10):
    
    global dga_predictions
    global pred_bb_series
    global pred_bb
    global dtrain_predictions
    
    if useTrainCV:
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(X_train.values, label=y_train)
        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,
            metrics='auc', early_stopping_rounds=early_stopping_rounds)
        alg.set_params(n_estimators=cvresult.shape[0])
    
    #Fit the algorithm on the data
    alg.fit(X_train, y_train,eval_metric='auc')
        
    #Predict training set:
    dtrain_predictions = alg.predict(X_train)
    dtest_predictions = alg.predict(X_test)
    dga_predictions = alg.predict(ga_process)
    pred_bb_series = pd.Series(dga_predictions)
    pred_bb_series.name="p_{}".format(tenure)
    pred_bb=ga_process.merge(pred_bb_series, how='left', left_index=True, right_index=True)
    #dtrain_predprob = alg.predict_proba(X_train[predictors])[:,1]
        
    #Print model report:
    print ("\nvModel Report")
   # print ("Accuracy : %.4g" % metrics.accuracy_score(y_train, dtrain_predictions))
    print ("AUC Score (Train): %f" % roc_auc_score(y_train, dtrain_predictions))
    print ("AUC Score (Test): %f" % roc_auc_score(y_test, dtest_predictions))
    
    plot_importance(alg,max_num_features=20)
    pyplot.show()
    
#Choose all predictors 
predictors = X_train.columns    
modelfit(xgb1, X_train,y_train, X_test,y_test,predictors,useTrainCV=False, cv_folds=5, early_stopping_rounds=10)
